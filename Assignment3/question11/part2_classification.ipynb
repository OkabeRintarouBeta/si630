{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32947ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48bd60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa01a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import krippendorff\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6deac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: krippendorff in /home/zihuiliu/.local/lib/python3.8/site-packages (0.5.1)\n",
      "Requirement already satisfied: numpy in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from krippendorff) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45fe4e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5533994185360147"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"../alldata/zihui_thomas_annotations.csv\")\n",
    "df1=df[df['annotator']=='user1']\n",
    "df2=df[df['annotator']=='user2']\n",
    "corr,_=pearsonr(df1['rating'],df2['rating'])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664a9cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1587553189685863\n",
      "0.42413933141329196\n"
     ]
    }
   ],
   "source": [
    "arr=[df1['rating'].values,df2['rating'].values]\n",
    "print(krippendorff.alpha(reliability_data=arr,level_of_measurement='nominal'))\n",
    "print(krippendorff.alpha(reliability_data=arr,level_of_measurement='ordinal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a618c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=pd.read_csv('../alldata/si630w22-hw3-data.csv')\n",
    "train_all=pd.read_csv('../alldata/si630w22-hw3-train.csv')\n",
    "train_all=train_all.rename(columns={'id':'question_id'})\n",
    "dev_all=pd.read_csv('../alldata/si630w22-hw3-dev.csv')\n",
    "dev_all=dev_all.rename(columns={'id':'question_id'})\n",
    "test_all=pd.read_csv('../alldata/si630w22-hw3-test.public.csv')\n",
    "test_all=test_all.rename(columns={'id':'question_id'})\n",
    "train_df=pd.merge(train_all,data_all,on='question_id')\n",
    "dev_df=pd.merge(dev_all,data_all,on='question_id')\n",
    "test_df=pd.merge(test_all,data_all,on='question_id')\n",
    "\n",
    "train_all.dropna(inplace=True)\n",
    "dev_all.dropna(inplace=True)\n",
    "test_all.dropna(inplace=True)\n",
    "train_all=train_all[(train_all['rating']<=5) & (train_all['rating']>0) & (train_all['rating']!='')]\n",
    "dev_all=dev_all[(dev_all['rating']<=5) & (dev_all['rating']>0)& (dev_all['rating']!='')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe7a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example:\n",
    "    def __init__(self,question_id,user_id,question,answer,label=None):\n",
    "        self.question_id=question_id\n",
    "        self.user_id=user_id\n",
    "        self.question=question\n",
    "        self.answer=answer\n",
    "        self.label=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdbfa51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_input(df):\n",
    "    question_list=[]\n",
    "    input_list=[]\n",
    "    for idx,row in df.iterrows():\n",
    "        user_id=row['annotator_id']\n",
    "        question_id=row['question_id']\n",
    "        if 'rating' in df.columns:\n",
    "#             print(row['rating'])\n",
    "            if row['rating']==1 or row['rating']==2 or row['rating']==3 or row['rating']==4 or row['rating']==5:\n",
    "                rating=int(row['rating'])-1\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            rating=None\n",
    "        question=row['question_text']\n",
    "        answer=row['reply_text']\n",
    "#         print(question_id,rating,question,answer)\n",
    "        \n",
    "        example=Example(question_id,user_id,question,answer,rating)\n",
    "        input_list.append(example)\n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d141f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../model/MiniLM-L12-H384-uncased/ and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=384, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "\n",
    "model_path=\"../model/MiniLM-L12-H384-uncased/\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=5)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c371f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sequence(input_list,tokenizer,max_length=128):\n",
    "    X_list=[]\n",
    "    label_list=[]\n",
    "    for example in input_list:\n",
    "        x=example.user_id+\"['[SEP]']\"+example.question+\"['[SEP]']\"+example.answer\n",
    "        label=example.label\n",
    "        label_list.append(label)\n",
    "        X_list.append(x)\n",
    "#     print(X_list)\n",
    "    X_train=tokenizer(X_list,padding=True,truncation=True,max_length=max_length)\n",
    "\n",
    "    return X_train,label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4159345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_list=to_input(train_df)\n",
    "val_input_list=to_input(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf9194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_list=to_input(test_df)\n",
    "X_test,Y_test=to_sequence(test_input_list,tokenizer,max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc460c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train=to_sequence(train_input_list,tokenizer,max_length=128)\n",
    "X_val,Y_val=to_sequence(val_input_list,tokenizer,max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef72247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "256412b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=Dataset(X_train,Y_train)\n",
    "val_dataset = Dataset(X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37d2da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "#     recall = recall_score(y_true=labels, y_pred=pred)\n",
    "#     precision = precision_score(y_true=labels, y_pred=pred)\n",
    "#     f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acdca859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zihuiliu/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 17836\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22300' max='22300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22300/22300 25:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.330600</td>\n",
       "      <td>1.281912</td>\n",
       "      <td>0.448502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.218300</td>\n",
       "      <td>1.214335</td>\n",
       "      <td>0.485549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.178400</td>\n",
       "      <td>1.141844</td>\n",
       "      <td>0.538098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>1.183500</td>\n",
       "      <td>0.528376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.122300</td>\n",
       "      <td>1.198128</td>\n",
       "      <td>0.532580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.105300</td>\n",
       "      <td>1.126477</td>\n",
       "      <td>0.563847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.094500</td>\n",
       "      <td>1.113546</td>\n",
       "      <td>0.557278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.074300</td>\n",
       "      <td>1.132826</td>\n",
       "      <td>0.559643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.080500</td>\n",
       "      <td>1.132054</td>\n",
       "      <td>0.561219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.017400</td>\n",
       "      <td>1.142129</td>\n",
       "      <td>0.551498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.013300</td>\n",
       "      <td>1.138849</td>\n",
       "      <td>0.563058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.029500</td>\n",
       "      <td>1.168504</td>\n",
       "      <td>0.544929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.049400</td>\n",
       "      <td>1.153793</td>\n",
       "      <td>0.558592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.024300</td>\n",
       "      <td>1.192059</td>\n",
       "      <td>0.554651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.003200</td>\n",
       "      <td>1.203571</td>\n",
       "      <td>0.536259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.973900</td>\n",
       "      <td>1.196086</td>\n",
       "      <td>0.539937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.148454</td>\n",
       "      <td>0.559905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.965500</td>\n",
       "      <td>1.132274</td>\n",
       "      <td>0.557803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.922800</td>\n",
       "      <td>1.220091</td>\n",
       "      <td>0.545717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>1.188106</td>\n",
       "      <td>0.551498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.942100</td>\n",
       "      <td>1.210493</td>\n",
       "      <td>0.545980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.931200</td>\n",
       "      <td>1.177085</td>\n",
       "      <td>0.557278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.891600</td>\n",
       "      <td>1.159456</td>\n",
       "      <td>0.568839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.881400</td>\n",
       "      <td>1.182949</td>\n",
       "      <td>0.567788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.897400</td>\n",
       "      <td>1.196818</td>\n",
       "      <td>0.574094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.898900</td>\n",
       "      <td>1.174340</td>\n",
       "      <td>0.567788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.860200</td>\n",
       "      <td>1.195275</td>\n",
       "      <td>0.556752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.853400</td>\n",
       "      <td>1.178787</td>\n",
       "      <td>0.573568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.829900</td>\n",
       "      <td>1.160763</td>\n",
       "      <td>0.567525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.847300</td>\n",
       "      <td>1.179493</td>\n",
       "      <td>0.566737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.822400</td>\n",
       "      <td>1.219094</td>\n",
       "      <td>0.568576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.802500</td>\n",
       "      <td>1.244914</td>\n",
       "      <td>0.559905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.824300</td>\n",
       "      <td>1.259250</td>\n",
       "      <td>0.547556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>1.296027</td>\n",
       "      <td>0.550709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.775700</td>\n",
       "      <td>1.244573</td>\n",
       "      <td>0.568576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.793300</td>\n",
       "      <td>1.251837</td>\n",
       "      <td>0.566737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>1.284692</td>\n",
       "      <td>0.569101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>1.236013</td>\n",
       "      <td>0.575670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.769400</td>\n",
       "      <td>1.278993</td>\n",
       "      <td>0.566474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.757500</td>\n",
       "      <td>1.277607</td>\n",
       "      <td>0.559380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.763800</td>\n",
       "      <td>1.256522</td>\n",
       "      <td>0.559643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.766800</td>\n",
       "      <td>1.295835</td>\n",
       "      <td>0.561745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.738900</td>\n",
       "      <td>1.299152</td>\n",
       "      <td>0.565423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.748300</td>\n",
       "      <td>1.293269</td>\n",
       "      <td>0.562007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-500\n",
      "Configuration saved in output/checkpoint-500/config.json\n",
      "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-1000\n",
      "Configuration saved in output/checkpoint-1000/config.json\n",
      "Model weights saved in output/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-1500\n",
      "Configuration saved in output/checkpoint-1500/config.json\n",
      "Model weights saved in output/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-2000\n",
      "Configuration saved in output/checkpoint-2000/config.json\n",
      "Model weights saved in output/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-2500\n",
      "Configuration saved in output/checkpoint-2500/config.json\n",
      "Model weights saved in output/checkpoint-2500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-3000\n",
      "Configuration saved in output/checkpoint-3000/config.json\n",
      "Model weights saved in output/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-3500\n",
      "Configuration saved in output/checkpoint-3500/config.json\n",
      "Model weights saved in output/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-4000\n",
      "Configuration saved in output/checkpoint-4000/config.json\n",
      "Model weights saved in output/checkpoint-4000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-4500\n",
      "Configuration saved in output/checkpoint-4500/config.json\n",
      "Model weights saved in output/checkpoint-4500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-5000\n",
      "Configuration saved in output/checkpoint-5000/config.json\n",
      "Model weights saved in output/checkpoint-5000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-5500\n",
      "Configuration saved in output/checkpoint-5500/config.json\n",
      "Model weights saved in output/checkpoint-5500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-6000\n",
      "Configuration saved in output/checkpoint-6000/config.json\n",
      "Model weights saved in output/checkpoint-6000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-6500\n",
      "Configuration saved in output/checkpoint-6500/config.json\n",
      "Model weights saved in output/checkpoint-6500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-7000\n",
      "Configuration saved in output/checkpoint-7000/config.json\n",
      "Model weights saved in output/checkpoint-7000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-7500\n",
      "Configuration saved in output/checkpoint-7500/config.json\n",
      "Model weights saved in output/checkpoint-7500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-8000\n",
      "Configuration saved in output/checkpoint-8000/config.json\n",
      "Model weights saved in output/checkpoint-8000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-8500\n",
      "Configuration saved in output/checkpoint-8500/config.json\n",
      "Model weights saved in output/checkpoint-8500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-9000\n",
      "Configuration saved in output/checkpoint-9000/config.json\n",
      "Model weights saved in output/checkpoint-9000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-9500\n",
      "Configuration saved in output/checkpoint-9500/config.json\n",
      "Model weights saved in output/checkpoint-9500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-10000\n",
      "Configuration saved in output/checkpoint-10000/config.json\n",
      "Model weights saved in output/checkpoint-10000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-10500\n",
      "Configuration saved in output/checkpoint-10500/config.json\n",
      "Model weights saved in output/checkpoint-10500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-11000\n",
      "Configuration saved in output/checkpoint-11000/config.json\n",
      "Model weights saved in output/checkpoint-11000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-11500\n",
      "Configuration saved in output/checkpoint-11500/config.json\n",
      "Model weights saved in output/checkpoint-11500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-12000\n",
      "Configuration saved in output/checkpoint-12000/config.json\n",
      "Model weights saved in output/checkpoint-12000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-12500\n",
      "Configuration saved in output/checkpoint-12500/config.json\n",
      "Model weights saved in output/checkpoint-12500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-13000\n",
      "Configuration saved in output/checkpoint-13000/config.json\n",
      "Model weights saved in output/checkpoint-13000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-13500\n",
      "Configuration saved in output/checkpoint-13500/config.json\n",
      "Model weights saved in output/checkpoint-13500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-14000\n",
      "Configuration saved in output/checkpoint-14000/config.json\n",
      "Model weights saved in output/checkpoint-14000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-14500\n",
      "Configuration saved in output/checkpoint-14500/config.json\n",
      "Model weights saved in output/checkpoint-14500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-15000\n",
      "Configuration saved in output/checkpoint-15000/config.json\n",
      "Model weights saved in output/checkpoint-15000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-15500\n",
      "Configuration saved in output/checkpoint-15500/config.json\n",
      "Model weights saved in output/checkpoint-15500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-16000\n",
      "Configuration saved in output/checkpoint-16000/config.json\n",
      "Model weights saved in output/checkpoint-16000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-16500\n",
      "Configuration saved in output/checkpoint-16500/config.json\n",
      "Model weights saved in output/checkpoint-16500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-17000\n",
      "Configuration saved in output/checkpoint-17000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/checkpoint-17000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-17500\n",
      "Configuration saved in output/checkpoint-17500/config.json\n",
      "Model weights saved in output/checkpoint-17500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-18000\n",
      "Configuration saved in output/checkpoint-18000/config.json\n",
      "Model weights saved in output/checkpoint-18000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-18500\n",
      "Configuration saved in output/checkpoint-18500/config.json\n",
      "Model weights saved in output/checkpoint-18500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-19000\n",
      "Configuration saved in output/checkpoint-19000/config.json\n",
      "Model weights saved in output/checkpoint-19000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-19500\n",
      "Configuration saved in output/checkpoint-19500/config.json\n",
      "Model weights saved in output/checkpoint-19500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-20000\n",
      "Configuration saved in output/checkpoint-20000/config.json\n",
      "Model weights saved in output/checkpoint-20000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-20500\n",
      "Configuration saved in output/checkpoint-20500/config.json\n",
      "Model weights saved in output/checkpoint-20500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-21000\n",
      "Configuration saved in output/checkpoint-21000/config.json\n",
      "Model weights saved in output/checkpoint-21000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-21500\n",
      "Configuration saved in output/checkpoint-21500/config.json\n",
      "Model weights saved in output/checkpoint-21500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3806\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-22000\n",
      "Configuration saved in output/checkpoint-22000/config.json\n",
      "Model weights saved in output/checkpoint-22000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from output/checkpoint-3500 (score: 1.1135456562042236).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=22300, training_loss=0.9295498629856537, metrics={'train_runtime': 1505.0664, 'train_samples_per_second': 118.506, 'train_steps_per_second': 14.817, 'total_flos': 2937423248148480.0, 'train_loss': 0.9295498629856537, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    seed=0,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "#     callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n",
    "\n",
    "# Train pre-trained model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "827820a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sequence_test(input_list,tokenizer,max_length=128):\n",
    "    X_list=[]\n",
    "#     label_list=[]\n",
    "    for example in input_list:\n",
    "        x=example.user_id+\"['[SEP]']\"+example.question+\"['[SEP]']\"+example.answer\n",
    "#         label=example.label\n",
    "#         label_list.append(label)\n",
    "        X_list.append(x)\n",
    "#     print(X_list)\n",
    "    X_train=tokenizer(X_list,padding=True,truncation=True,max_length=max_length)\n",
    "\n",
    "    return X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0afa3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_list=to_input(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d604627",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=to_sequence(test_input_list,tokenizer,max_length=128)\n",
    "X_test=X_test[0]\n",
    "test_dataset=Dataset(X_test,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13cbdf8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 3821\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='478' max='478' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [478/478 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_test_result,_,_=trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(raw_test_result, axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e57b4598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdbb13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list=[]\n",
    "for item in y_pred:\n",
    "    pred_list.append((round)(item))\n",
    "\n",
    "test_result=test_all.rename(columns={'question_id':'id'})\n",
    "test_result['rating']=pred_list\n",
    "test_result.to_csv('test_result_classification_batch8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225dc51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
